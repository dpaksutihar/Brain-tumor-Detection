# -*- coding: utf-8 -*-
"""train_unet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pUWg2u8-27GN3mKE9fd_oq3Y7dt3lQ-f
"""

# !unzip '/content/drive/MyDrive/Brain MRI Classification_segmentation/segmentation/segmentation_data.zip' -d ''

import os
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras import layers, Model
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tensorflow.keras.utils import Sequence
import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras import layers, Model
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import backend as K

# Paths to dataset
IMAGE_DIR = "/content/segmentation_data/images"
MASK_DIR = "/content/segmentation_data/masks"
model_save_path = '/content/drive/MyDrive/Brain MRI Classification_segmentation/segmentation'
# Image dimensions & batch size
IMG_HEIGHT, IMG_WIDTH = 256, 256
BATCH_SIZE = 16
EPOCHS = 30

from tensorflow.keras import backend as K

def binary_crossentropy(y_true, y_pred, pos_weight=15):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())  # Avoid log(0)

    # Calculate the weighted binary cross-entropy
    loss = - (pos_weight * y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))
    return tf.reduce_mean(loss)
# Additional metrics
def iou_metric(y_true, y_pred, pos_weight=1):
    # Cast to float32
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)

    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection

    # Increase weight for positive class (1s)
    weighted_iou = intersection / (union + tf.keras.backend.epsilon()) * pos_weight
    return weighted_iou


def dice_coefficient(y_true, y_pred, pos_weight=1):
    # Cast to float32
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)

    intersection = tf.reduce_sum(y_true * y_pred)
    dice = (2 * intersection + tf.keras.backend.epsilon()) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + tf.keras.backend.epsilon())

    # Increase weight for positive class (1s)
    weighted_dice = dice * pos_weight
    return weighted_dice

# Get class names (folders in images/masks directory)
class_names = sorted(os.listdir(IMAGE_DIR))

# Function to get all image/mask paths
def get_image_paths(image_dir, mask_dir, class_names):
    image_paths, mask_paths = [], []
    for class_name in class_names:
        img_folder = os.path.join(image_dir, class_name)
        mask_folder = os.path.join(mask_dir, class_name)

        for filename in os.listdir(img_folder):
            image_paths.append(os.path.join(img_folder, filename))
            mask_paths.append(os.path.join(mask_folder, filename))

    return image_paths, mask_paths

# Load image & mask file paths
image_paths, mask_paths = get_image_paths(IMAGE_DIR, MASK_DIR, class_names)

# Split into train (70%), val (20%), test (10%)
train_imgs, temp_imgs, train_masks, temp_masks = train_test_split(image_paths, mask_paths, test_size=0.3, random_state=42)
val_imgs, test_imgs, val_masks, test_masks = train_test_split(temp_imgs, temp_masks, test_size=1/3, random_state=42)

print(f"Train: {len(train_imgs)}, Val: {len(val_imgs)}, Test: {len(test_imgs)}")

# Data Generator
class ImageMaskGenerator(Sequence):
    def __init__(self, image_paths, mask_paths, batch_size, img_size=(IMG_HEIGHT, IMG_WIDTH), shuffle=True,
                 **kwargs):
        super().__init__(**kwargs)
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.batch_size = batch_size
        self.img_size = img_size
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.image_paths) / self.batch_size))

    def __getitem__(self, index):
        batch_image_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]
        batch_mask_paths = self.mask_paths[index * self.batch_size:(index + 1) * self.batch_size]

        images, masks = self.__load_batch(batch_image_paths, batch_mask_paths)
        return np.array(images), np.array(masks)

    def __load_batch(self, image_paths, mask_paths):
        images, masks = [], []
        for img_path, mask_path in zip(image_paths, mask_paths):
            image = cv2.imread(img_path, cv2.IMREAD_COLOR)
            image = cv2.resize(image, self.img_size)
            image = image / 255.0  # Normalize

            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            mask = cv2.resize(mask, self.img_size)
            mask = np.expand_dims(mask, axis=-1)  # Add channel dimension
            mask = mask / 255.0  # Normalize to [0,1]

            images.append(image)
            masks.append(mask)

        return images, masks

    def on_epoch_end(self):
        if self.shuffle:
            combined = list(zip(self.image_paths, self.mask_paths))
            np.random.shuffle(combined)
            self.image_paths, self.mask_paths = zip(*combined)

# U-Net Model
def unet_model(input_size=(IMG_HEIGHT, IMG_WIDTH, 3)):
    inputs = layers.Input(input_size)

    # Encoder (Downsampling)
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)

    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)

    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D((2, 2))(c3)

    # Bottleneck
    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)

    # Decoder (Upsampling)
    u1 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)
    u1 = layers.concatenate([u1, c3])
    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u1)
    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)

    u2 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    u2 = layers.concatenate([u2, c2])
    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u2)
    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)

    u3 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    u3 = layers.concatenate([u3, c1])
    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u3)
    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c7)

    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c7)

    model = Model(inputs, outputs)
    return model

# Create generators
train_gen = ImageMaskGenerator(train_imgs, train_masks, BATCH_SIZE)
val_gen = ImageMaskGenerator(val_imgs, val_masks, BATCH_SIZE)
test_gen = ImageMaskGenerator(test_imgs, test_masks, BATCH_SIZE, shuffle=False)

# Compile model with additional metrics
model = unet_model()
model.compile(optimizer='adam',
              loss=binary_crossentropy,
              metrics=['accuracy', iou_metric, dice_coefficient])

print(model.summary())

# Callbacks
checkpoint = ModelCheckpoint(os.path.join(model_save_path,"best_unet_segmentation_model.keras"),
                             save_best_only=True,
                             save_weights_only=False,
                             monitor="val_loss",
                             mode="min",
                             verbose=1)

early_stop = EarlyStopping(monitor="val_loss",
                           patience=5,
                           restore_best_weights=True,
                           verbose=1)

reduce_lr = ReduceLROnPlateau(monitor="val_loss",
                              factor=0.1,
                              patience=3,
                              min_lr=1e-6,
                              verbose=1)

# Train model using generator
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=EPOCHS,
    callbacks=[checkpoint, early_stop, reduce_lr],
)

# Save final trained model
# model.save("unet_segmentation_model_last.keras")
print("Model training complete and saved!")

# Plot training history
plt.figure(figsize=(12, 4))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label="Train Accuracy")
plt.plot(history.history['val_accuracy'], label="Val Accuracy")
plt.legend()
plt.title("Accuracy")

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label="Train Loss")
plt.plot(history.history['val_loss'], label="Val Loss")
plt.legend()
plt.title("Loss")

plt.show()

# Optionally, you can plot IoU and Dice
plt.figure(figsize=(12, 4))

# IoU Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['iou_metric'], label="Train IoU")
plt.plot(history.history['val_iou_metric'], label="Val IoU")
plt.legend()
plt.title("IoU Metric")

# Dice Coefficient Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['dice_coefficient'], label="Train Dice")
plt.plot(history.history['val_dice_coefficient'], label="Val Dice")
plt.legend()
plt.title("Dice Coefficient")

plt.show()

# Evaluate on test set
test_loss, test_acc, test_iou, test_dice = model.evaluate(test_gen)
print(f"Test Accuracy: {test_acc:.2f}")
print(f"Test IoU: {test_iou:.2f}")
print(f"Test Dice Coefficient: {test_dice:.2f}")

